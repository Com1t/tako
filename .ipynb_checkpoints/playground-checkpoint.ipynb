{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d196e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原來的df\n",
      "Empty DataFrame\n",
      "Columns: [name, math, chinese]\n",
      "Index: []\n",
      "=================================\n",
      "新增一筆資料\n",
      "    name math chinese  connectivity   cpu\n",
      "0  Henry   60     NaN          60.0  30.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=[\"name\", \"math\", \"chinese\"])\n",
    "print(\"原來的df\")\n",
    "print(df)\n",
    " \n",
    "print(\"=================================\")\n",
    " \n",
    "new_df = df.append({\n",
    "    \"name\": \"Henry\",\n",
    "    \"math\": 60,\n",
    "    \"cpu\": 30,\n",
    "    \"connectivity\": 60\n",
    "}, ignore_index=True)\n",
    " \n",
    "print(\"新增一筆資料\")\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4daeaadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "context = []\n",
    "print(len(context))\n",
    "context.append(1)\n",
    "print(len(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44bb233e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-22T14:50:00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "now = np.datetime64('now') # timestamp right now \n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d8f9005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "past = now - np.timedelta64(1,'m')\n",
    "now = np.datetime64('now')\n",
    "\n",
    "\n",
    "print((now - past) > np.timedelta64(1,'m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa8abc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = np.dtype(\n",
    "    [\n",
    "        (\"ip\", str),\n",
    "        (\"port\", int),\n",
    "        (\"status\", str),\n",
    "        (\"heartbeat\", np.datetime64),\n",
    "    ]\n",
    ")\n",
    "# client database\n",
    "df = pd.DataFrame(np.empty(0, dtype=dtypes))\n",
    "\n",
    "for i in range(10):\n",
    "    recv_df = pd.DataFrame({\n",
    "        \"ip\": \"127.0.0.1\",\n",
    "        \"port\": 12314 + i,\n",
    "        \"cpu\": 30, \n",
    "        \"gradient_norm\": 0.0,\n",
    "        \"data amount\": 0,\n",
    "        \"connectivity\": 60\n",
    "    }, index=[0])\n",
    "    df = df.append(recv_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a7d51311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ip   port status heartbeat   cpu  gradient_norm  data amount  \\\n",
      "0  127.0.0.1  12314    NaN       NaT  30.0            0.0          0.0   \n",
      "1  127.0.0.1  12315    NaN       NaT  30.0            0.0          0.0   \n",
      "2  127.0.0.1  12316    NaN       NaT  30.0            0.0          0.0   \n",
      "3  127.0.0.1  12317    NaN       NaT  30.0            0.0          0.0   \n",
      "4  127.0.0.1  12318    NaN       NaT  30.0            0.0          0.0   \n",
      "5  127.0.0.1  12319    NaN       NaT  30.0            0.0          0.0   \n",
      "6  127.0.0.1  12320    NaN       NaT  30.0            0.0          0.0   \n",
      "7  127.0.0.1  12321    NaN       NaT  30.0            0.0          0.0   \n",
      "8  127.0.0.1  12322    NaN       NaT  30.0            0.0          0.0   \n",
      "9  127.0.0.1  12323    NaN       NaT  30.0            0.0          0.0   \n",
      "\n",
      "   connectivity  \n",
      "0          60.0  \n",
      "1          60.0  \n",
      "2          60.0  \n",
      "3          60.0  \n",
      "4          60.0  \n",
      "5          60.0  \n",
      "6          60.0  \n",
      "7          60.0  \n",
      "8          60.0  \n",
      "9          60.0  \n",
      "          ip   port             status heartbeat   cpu  gradient_norm  \\\n",
      "0  127.0.0.1  12314  selected training       NaT  30.0            0.0   \n",
      "1  127.0.0.1  12315  selected training       NaT  30.0            0.0   \n",
      "2  127.0.0.1  12316                NaN       NaT  30.0            0.0   \n",
      "3  127.0.0.1  12317  selected training       NaT  30.0            0.0   \n",
      "4  127.0.0.1  12318                NaN       NaT  30.0            0.0   \n",
      "5  127.0.0.1  12319  selected training       NaT  30.0            0.0   \n",
      "6  127.0.0.1  12320  selected training       NaT  30.0            0.0   \n",
      "7  127.0.0.1  12321                NaN       NaT  30.0            0.0   \n",
      "8  127.0.0.1  12322                NaN       NaT  30.0            0.0   \n",
      "9  127.0.0.1  12323                NaN       NaT  30.0            0.0   \n",
      "\n",
      "   data amount  connectivity  \n",
      "0          0.0          60.0  \n",
      "1          0.0          60.0  \n",
      "2          0.0          60.0  \n",
      "3          0.0          60.0  \n",
      "4          0.0          60.0  \n",
      "5          0.0          60.0  \n",
      "6          0.0          60.0  \n",
      "7          0.0          60.0  \n",
      "8          0.0          60.0  \n",
      "9          0.0          60.0  \n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "df.iloc[df.sample(frac = 0.5).index,df.columns.get_loc('status')] = 'selected training'\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8d2e1d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ip   port             status heartbeat   cpu  gradient_norm  \\\n",
      "0  127.0.0.1  12314  selected training       NaT  30.0            0.0   \n",
      "1  127.0.0.1  12315  selected training       NaT  30.0            0.0   \n",
      "2  127.0.0.1  12316                NaN       NaT  30.0            0.0   \n",
      "3  127.0.0.1  12317  selected training       NaT  30.0            0.0   \n",
      "4  127.0.0.1  12318                NaN       NaT  30.0            0.0   \n",
      "5  127.0.0.1  12319  selected training       NaT  30.0            0.0   \n",
      "6  127.0.0.1  12320  selected training       NaT  30.0            0.0   \n",
      "7  127.0.0.1  12321                NaN       NaT  30.0            0.0   \n",
      "8  127.0.0.1  12322                NaN       NaT  30.0            0.0   \n",
      "9  127.0.0.1  12323                NaN       NaT  30.0            0.0   \n",
      "\n",
      "   data amount  connectivity  \n",
      "0          0.0          60.0  \n",
      "1          0.0          60.0  \n",
      "2          0.0          60.0  \n",
      "3          0.0          60.0  \n",
      "4          0.0          60.0  \n",
      "5          0.0          60.0  \n",
      "6          0.0          60.0  \n",
      "7          0.0          60.0  \n",
      "8          0.0          60.0  \n",
      "9          0.0          60.0  \n",
      "          ip   port             status heartbeat   cpu  gradient_norm  \\\n",
      "0  127.0.0.1  12314           training       NaT  30.0            0.0   \n",
      "1  127.0.0.1  12315           training       NaT  30.0            0.0   \n",
      "2  127.0.0.1  12316                NaN       NaT  30.0            0.0   \n",
      "3  127.0.0.1  12317           training       NaT  30.0            0.0   \n",
      "4  127.0.0.1  12318           training       NaT  30.0            0.0   \n",
      "5  127.0.0.1  12319  selected training       NaT  30.0            0.0   \n",
      "6  127.0.0.1  12320  selected training       NaT  30.0            0.0   \n",
      "7  127.0.0.1  12321                NaN       NaT  30.0            0.0   \n",
      "8  127.0.0.1  12322                NaN       NaT  30.0            0.0   \n",
      "9  127.0.0.1  12323           training       NaT  30.0            0.0   \n",
      "\n",
      "   data amount  connectivity  \n",
      "0          0.0          60.0  \n",
      "1          0.0          60.0  \n",
      "2          0.0          60.0  \n",
      "3          0.0          60.0  \n",
      "4          0.0          60.0  \n",
      "5          0.0          60.0  \n",
      "6          0.0          60.0  \n",
      "7          0.0          60.0  \n",
      "8          0.0          60.0  \n",
      "9          0.0          60.0  \n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "df.iloc[df.sample(frac = 0.5).index,df.columns.get_loc('status')] = 'training'\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8164e80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ip   port             status heartbeat   cpu  gradient_norm  \\\n",
      "0  127.0.0.1  12314           training       NaT  30.0            0.0   \n",
      "1  127.0.0.1  12315           training       NaT  30.0            0.0   \n",
      "3  127.0.0.1  12317           training       NaT  30.0            0.0   \n",
      "4  127.0.0.1  12318           training       NaT  30.0            0.0   \n",
      "5  127.0.0.1  12319  selected training       NaT  30.0            0.0   \n",
      "6  127.0.0.1  12320  selected training       NaT  30.0            0.0   \n",
      "9  127.0.0.1  12323           training       NaT  30.0            0.0   \n",
      "\n",
      "   data amount  connectivity  \n",
      "0          0.0          60.0  \n",
      "1          0.0          60.0  \n",
      "3          0.0          60.0  \n",
      "4          0.0          60.0  \n",
      "5          0.0          60.0  \n",
      "6          0.0          60.0  \n",
      "9          0.0          60.0  \n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d8f89b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Element: 7\n",
      "Updated List: [2, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "# create a list of prime numbers\n",
    "prime_numbers = [2, 3, 5, 7]\n",
    "\n",
    "# remove the element at index 2\n",
    "removed_element = prime_numbers.pop()\n",
    "\n",
    "print('Removed Element:', removed_element)\n",
    "print('Updated List:', prime_numbers)\n",
    "\n",
    "# Output: \n",
    "# Removed Element: 5\n",
    "# Updated List: [2, 3, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f8062726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "print(type(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e0e2f37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU State: cuda:0\n",
      "MNIST_NN(\n",
      "  (conv_1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv_2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (linear_1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (linear_2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "True\n",
      "Epoch [1/3], Step [100], Loss: 0.1182, Acc : 0.9667\n",
      "Epoch [1/3], Step [200], Loss: 0.0688, Acc : 0.9819\n",
      "0.10301096185724785\n",
      "189.84357274712724\n",
      "Epoch [2/3], Step [100], Loss: 0.0174, Acc : 0.9852\n",
      "Epoch [2/3], Step [200], Loss: 0.0311, Acc : 0.9876\n",
      "0.08873310089111328\n",
      "110.63426963375966\n",
      "Epoch [3/3], Step [100], Loss: 0.0636, Acc : 0.9895\n",
      "Epoch [3/3], Step [200], Loss: 0.0390, Acc : 0.9891\n",
      "0.08574970427979814\n",
      "93.96117211003639\n",
      "65.21312665939331\n",
      "OrderedDict([('conv_1.weight', tensor([[[[ 0.0792, -0.1351, -0.1442, -0.0511, -0.2592],\n",
      "          [ 0.1619,  0.0432,  0.1094,  0.0134, -0.0706],\n",
      "          [ 0.1025,  0.1483,  0.2174,  0.0686,  0.0580],\n",
      "          [-0.0624,  0.0782,  0.0799,  0.2654,  0.1740],\n",
      "          [-0.1327, -0.1819, -0.1411, -0.1485,  0.0054]]],\n",
      "\n",
      "\n",
      "        [[[-0.0201,  0.1636,  0.1380, -0.2629,  0.0714],\n",
      "          [ 0.0441,  0.2439,  0.1280, -0.2631, -0.2352],\n",
      "          [-0.0597,  0.2422, -0.0352,  0.0034, -0.1442],\n",
      "          [ 0.2067, -0.0521,  0.1727, -0.0323, -0.1297],\n",
      "          [ 0.1014, -0.0861,  0.0974, -0.0496, -0.0324]]],\n",
      "\n",
      "\n",
      "        [[[-0.1892, -0.1196,  0.0554, -0.0429,  0.2401],\n",
      "          [ 0.1295, -0.0598, -0.1177,  0.2133,  0.1228],\n",
      "          [-0.1450,  0.1200,  0.1889,  0.2483, -0.1412],\n",
      "          [-0.0332,  0.0254,  0.0538, -0.1725, -0.2162],\n",
      "          [ 0.1003, -0.0609,  0.0575, -0.0470,  0.0352]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0838,  0.1348,  0.1473, -0.1464,  0.1290],\n",
      "          [-0.1175, -0.1430, -0.0034, -0.0101,  0.1787],\n",
      "          [-0.1094, -0.1855,  0.1210,  0.0136,  0.1494],\n",
      "          [ 0.0463, -0.1621,  0.0746,  0.0987, -0.1011],\n",
      "          [-0.0804,  0.0879,  0.0855, -0.0518, -0.0321]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1506,  0.0014,  0.1642,  0.0851, -0.1794],\n",
      "          [-0.2423,  0.2142,  0.0409,  0.0360, -0.0494],\n",
      "          [-0.0167,  0.1846,  0.2070, -0.2622, -0.0585],\n",
      "          [ 0.0798,  0.1786,  0.1392, -0.2319, -0.1973],\n",
      "          [-0.1217,  0.0755,  0.2540, -0.1494,  0.0631]]],\n",
      "\n",
      "\n",
      "        [[[-0.1432, -0.2543, -0.1250,  0.1343,  0.1875],\n",
      "          [-0.1735,  0.0065,  0.2532,  0.1851,  0.0651],\n",
      "          [ 0.1225,  0.1587,  0.0954, -0.1476, -0.2462],\n",
      "          [-0.0840, -0.0271, -0.1707,  0.0260,  0.0080],\n",
      "          [-0.0688,  0.0494,  0.0238,  0.0979,  0.0821]]],\n",
      "\n",
      "\n",
      "        [[[-0.0338,  0.2389,  0.0135, -0.0040, -0.1875],\n",
      "          [-0.1183, -0.1184, -0.0827,  0.1396, -0.0531],\n",
      "          [-0.1296,  0.0586,  0.0335,  0.1213, -0.0912],\n",
      "          [ 0.0953, -0.0822, -0.0769, -0.1649, -0.0804],\n",
      "          [ 0.0074,  0.1262,  0.0685,  0.0953,  0.2651]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1757,  0.1506,  0.0334, -0.1306,  0.1459],\n",
      "          [-0.0658, -0.0280, -0.1782, -0.0647, -0.1647],\n",
      "          [ 0.1763, -0.1885, -0.1686, -0.0477, -0.1300],\n",
      "          [ 0.0889, -0.0482, -0.0648,  0.0359,  0.2057],\n",
      "          [-0.1056,  0.1753,  0.2369,  0.2539, -0.1011]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0298, -0.1713,  0.2029, -0.0315,  0.0826],\n",
      "          [-0.0418, -0.0703, -0.0096,  0.1368,  0.1653],\n",
      "          [ 0.0124,  0.0094, -0.2623,  0.1719,  0.2759],\n",
      "          [ 0.1238,  0.0728, -0.2535, -0.1856,  0.2095],\n",
      "          [-0.2068,  0.1196, -0.2373, -0.2402,  0.0411]]],\n",
      "\n",
      "\n",
      "        [[[-0.1201,  0.0004,  0.2127,  0.2081,  0.2198],\n",
      "          [-0.0274, -0.1420,  0.2384, -0.0091, -0.0641],\n",
      "          [ 0.0482, -0.1636,  0.1349,  0.1622, -0.1224],\n",
      "          [-0.1837, -0.0632,  0.0632,  0.0169, -0.0837],\n",
      "          [-0.0303, -0.2357, -0.1518, -0.1130,  0.1588]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1674, -0.0206,  0.0605,  0.1061, -0.0245],\n",
      "          [-0.1261,  0.1333,  0.1501,  0.0272, -0.0455],\n",
      "          [ 0.1546,  0.1930, -0.0754,  0.2328,  0.0285],\n",
      "          [-0.1253,  0.1632, -0.0873,  0.2290, -0.1490],\n",
      "          [ 0.0703,  0.1394,  0.1168,  0.2059, -0.1138]]],\n",
      "\n",
      "\n",
      "        [[[-0.1080, -0.1559,  0.0869, -0.0266,  0.0237],\n",
      "          [-0.0802,  0.0507,  0.2442,  0.1036, -0.0566],\n",
      "          [-0.1322, -0.1850,  0.2339,  0.0134,  0.0503],\n",
      "          [-0.0216, -0.1307,  0.1640,  0.1643,  0.0399],\n",
      "          [-0.1507, -0.1133,  0.0442, -0.0556, -0.0867]]],\n",
      "\n",
      "\n",
      "        [[[-0.0260, -0.0561,  0.0638,  0.0215,  0.0542],\n",
      "          [-0.0828, -0.2062,  0.1240,  0.0584,  0.2485],\n",
      "          [-0.0471, -0.0762, -0.2049, -0.0130,  0.2220],\n",
      "          [-0.2173, -0.0978,  0.1061,  0.1447,  0.1311],\n",
      "          [-0.0655, -0.0301, -0.0150, -0.0262,  0.1327]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0310, -0.0357,  0.1029, -0.0774, -0.0012],\n",
      "          [ 0.1721,  0.1361,  0.2157, -0.0794,  0.0437],\n",
      "          [-0.0403, -0.0638, -0.0693,  0.0584,  0.0436],\n",
      "          [-0.1039, -0.1237, -0.1667,  0.1488, -0.0228],\n",
      "          [-0.0405, -0.0769, -0.1107, -0.1948, -0.0819]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1680,  0.1286,  0.0217, -0.0262,  0.1449],\n",
      "          [ 0.1820,  0.3055,  0.1744,  0.1750,  0.0286],\n",
      "          [-0.2008, -0.1957,  0.1284, -0.0435,  0.0804],\n",
      "          [-0.0593, -0.2477, -0.2006, -0.0407, -0.1007],\n",
      "          [-0.2317,  0.0114, -0.0764, -0.1456,  0.0140]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0086, -0.1222,  0.1833,  0.0670, -0.0272],\n",
      "          [-0.0670, -0.1797,  0.1522, -0.1469, -0.1975],\n",
      "          [ 0.1018,  0.0577,  0.0095, -0.1483, -0.1615],\n",
      "          [ 0.0112,  0.1761,  0.0643, -0.0814,  0.1678],\n",
      "          [-0.0426,  0.1740,  0.1227,  0.2427,  0.1642]]],\n",
      "\n",
      "\n",
      "        [[[-0.0894,  0.1388, -0.0103, -0.1731, -0.0485],\n",
      "          [-0.1699, -0.1034, -0.1549,  0.1341, -0.0303],\n",
      "          [ 0.0235,  0.1400,  0.0989, -0.1247,  0.0859],\n",
      "          [ 0.1485, -0.1067,  0.2081, -0.1167, -0.0857],\n",
      "          [-0.1424,  0.2010,  0.0746,  0.2188,  0.0670]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1168, -0.0677, -0.1788,  0.0094, -0.0133],\n",
      "          [-0.0362, -0.1369, -0.0211,  0.0672,  0.1063],\n",
      "          [-0.1374,  0.1301,  0.0900,  0.1951,  0.1740],\n",
      "          [-0.0971,  0.2511, -0.1440,  0.1366, -0.0019],\n",
      "          [ 0.1375, -0.1103,  0.0839, -0.1203, -0.1913]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0721,  0.1427,  0.2492,  0.0185,  0.1899],\n",
      "          [ 0.1539, -0.1122, -0.1411,  0.1288, -0.1358],\n",
      "          [ 0.1014, -0.2069,  0.1498,  0.0872, -0.0747],\n",
      "          [ 0.0812, -0.1615, -0.0282,  0.0316, -0.1586],\n",
      "          [-0.0353, -0.0805,  0.2026,  0.1939,  0.1646]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1690, -0.1722,  0.0566,  0.0351, -0.2300],\n",
      "          [ 0.0556, -0.1343, -0.0156,  0.1109,  0.2062],\n",
      "          [-0.1432, -0.1870,  0.2051,  0.1415,  0.1506],\n",
      "          [ 0.0575,  0.0031,  0.1400, -0.2405, -0.0196],\n",
      "          [ 0.1002,  0.1581, -0.1571, -0.1922,  0.0446]]],\n",
      "\n",
      "\n",
      "        [[[-0.1364, -0.1639, -0.1827, -0.0793,  0.0040],\n",
      "          [-0.1176, -0.1005, -0.1879,  0.1199, -0.0113],\n",
      "          [-0.1405,  0.0270, -0.1576,  0.1477,  0.1478],\n",
      "          [-0.1777, -0.1396, -0.1004, -0.0461,  0.0849],\n",
      "          [-0.1678, -0.1233,  0.1113, -0.0058, -0.0173]]],\n",
      "\n",
      "\n",
      "        [[[-0.1563,  0.0791,  0.0281, -0.0485, -0.0956],\n",
      "          [ 0.0500,  0.0673,  0.0839,  0.0755, -0.0053],\n",
      "          [-0.1214,  0.1359, -0.0296, -0.1350,  0.1757],\n",
      "          [ 0.1405, -0.1666, -0.1355, -0.0711, -0.1214],\n",
      "          [ 0.1339, -0.1102,  0.2389,  0.0019,  0.1704]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1053, -0.0289,  0.1603, -0.1323, -0.0994],\n",
      "          [ 0.0674,  0.1602, -0.1021, -0.1227, -0.1199],\n",
      "          [-0.0429, -0.0669, -0.0796, -0.1512,  0.0353],\n",
      "          [ 0.0183, -0.1366, -0.1364,  0.0094, -0.0248],\n",
      "          [ 0.1437, -0.0409, -0.1543, -0.1289, -0.0384]]],\n",
      "\n",
      "\n",
      "        [[[-0.0763, -0.0135, -0.0981,  0.0619, -0.0569],\n",
      "          [ 0.0889, -0.0310, -0.1615,  0.1719,  0.0539],\n",
      "          [-0.2071, -0.1866,  0.1234,  0.1217,  0.1316],\n",
      "          [-0.0727,  0.1629,  0.1410,  0.0748, -0.0751],\n",
      "          [ 0.2046,  0.0744, -0.0563, -0.0209,  0.1881]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1047,  0.0332,  0.2500,  0.0653, -0.1714],\n",
      "          [-0.2042,  0.1517,  0.2607, -0.1127,  0.0107],\n",
      "          [-0.0275, -0.0215,  0.0299,  0.0756, -0.0135],\n",
      "          [ 0.1062,  0.0789,  0.1431,  0.2022,  0.0611],\n",
      "          [ 0.0062, -0.0674,  0.1685,  0.0546,  0.1347]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1932, -0.0007,  0.2322,  0.0754,  0.2718],\n",
      "          [ 0.1311, -0.0788, -0.0122, -0.1148, -0.1139],\n",
      "          [-0.1051, -0.0585, -0.1449, -0.2441, -0.1555],\n",
      "          [-0.0591, -0.0869,  0.1129,  0.1645,  0.1383],\n",
      "          [ 0.0621, -0.1645,  0.1832, -0.1646, -0.0545]]],\n",
      "\n",
      "\n",
      "        [[[-0.1061,  0.1018, -0.1071, -0.0387, -0.0821],\n",
      "          [-0.1091, -0.0793,  0.2235, -0.0014,  0.0542],\n",
      "          [-0.1843,  0.2027, -0.0279, -0.1811,  0.1366],\n",
      "          [ 0.0035,  0.2339, -0.1191, -0.1527, -0.1016],\n",
      "          [ 0.1702,  0.0193, -0.1693,  0.0670,  0.0258]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1375, -0.0395, -0.0506,  0.1889, -0.0346],\n",
      "          [ 0.1531,  0.1585, -0.0961, -0.0765,  0.0153],\n",
      "          [-0.2021,  0.0252, -0.0911, -0.1113, -0.1699],\n",
      "          [ 0.0685, -0.1595, -0.1692, -0.0746, -0.0938],\n",
      "          [-0.1907,  0.0839, -0.0380,  0.1694,  0.1989]]],\n",
      "\n",
      "\n",
      "        [[[-0.1692, -0.1524, -0.0148,  0.2290,  0.0256],\n",
      "          [-0.1500,  0.0728,  0.2751,  0.2290, -0.2109],\n",
      "          [-0.0844,  0.0347,  0.2860, -0.0822, -0.1738],\n",
      "          [-0.0270,  0.0115,  0.1569, -0.0121, -0.1594],\n",
      "          [ 0.0764,  0.0967,  0.0508, -0.1953,  0.0524]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1342,  0.0292, -0.1896, -0.0549, -0.0900],\n",
      "          [ 0.2240,  0.2279, -0.0989, -0.2018,  0.0598],\n",
      "          [ 0.1128,  0.2524, -0.0917, -0.0110, -0.1583],\n",
      "          [-0.1725,  0.0087,  0.1854,  0.0767, -0.2242],\n",
      "          [ 0.0754,  0.1877,  0.2103,  0.1581, -0.0318]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1505,  0.1843,  0.1010, -0.1433, -0.0671],\n",
      "          [ 0.1654,  0.2142,  0.2182, -0.0345, -0.0409],\n",
      "          [-0.2296, -0.1292,  0.2517, -0.0792, -0.0472],\n",
      "          [-0.0262, -0.1776,  0.0743,  0.0406,  0.0862],\n",
      "          [-0.1884, -0.0052, -0.1786,  0.1432,  0.1790]]],\n",
      "\n",
      "\n",
      "        [[[-0.0155,  0.0488, -0.0973, -0.1485, -0.0978],\n",
      "          [-0.0534,  0.0328, -0.0473, -0.0390, -0.1401],\n",
      "          [-0.0920, -0.1749, -0.1394,  0.1558,  0.1309],\n",
      "          [-0.1366,  0.0341,  0.1155,  0.1727,  0.2421],\n",
      "          [ 0.1599,  0.2515,  0.0463,  0.0598, -0.0766]]]], device='cuda:0')), ('conv_1.bias', tensor([ 0.0351,  0.1789,  0.1049,  0.1046, -0.0785, -0.0221,  0.0133,  0.1460,\n",
      "        -0.1355, -0.1123,  0.0413, -0.1351,  0.0612, -0.0771, -0.0149,  0.0977,\n",
      "         0.1191,  0.1550,  0.0853, -0.0094,  0.1322,  0.1010, -0.1340,  0.1045,\n",
      "         0.0196, -0.0553, -0.1025, -0.0943, -0.1395, -0.0641,  0.0680,  0.0768],\n",
      "       device='cuda:0')), ('conv_2.weight', tensor([[[[ 3.4147e-02, -5.4924e-02, -1.2693e-02, -8.9971e-04,  5.5442e-02],\n",
      "          [-3.1922e-02, -4.4526e-02,  3.6287e-02,  5.5107e-02,  3.9566e-02],\n",
      "          [-6.2104e-02, -3.0341e-02,  2.5647e-03, -2.8302e-02, -1.3072e-02],\n",
      "          [-1.9450e-02,  2.0645e-02,  5.8953e-02, -4.8879e-03, -9.9304e-03],\n",
      "          [-5.4208e-02,  3.8064e-04,  1.0387e-02,  4.3152e-02, -2.2172e-02]],\n",
      "\n",
      "         [[-1.5139e-02, -7.0296e-02, -3.0692e-02,  3.5148e-02,  1.5794e-02],\n",
      "          [-5.5267e-02, -2.1713e-02, -5.6583e-03,  1.7805e-02, -5.5525e-04],\n",
      "          [-9.4419e-02, -1.7303e-03,  2.7569e-02, -4.9846e-02, -2.5472e-02],\n",
      "          [-1.7883e-02,  8.7220e-03, -2.1343e-03, -3.8351e-02, -6.2910e-02],\n",
      "          [-7.9405e-03, -3.2387e-02, -4.0678e-02, -7.6739e-03, -4.6652e-02]],\n",
      "\n",
      "         [[-1.9466e-02,  3.0039e-02,  5.5940e-02,  7.2107e-03,  6.5214e-02],\n",
      "          [-1.2924e-03,  1.9224e-02,  4.5793e-02,  6.9561e-02,  7.0634e-02],\n",
      "          [ 4.1910e-02,  4.7937e-02,  2.9041e-02,  1.4639e-02, -4.8775e-02],\n",
      "          [ 2.9090e-02, -3.3702e-02, -4.3169e-02, -7.5237e-02, -3.2492e-02],\n",
      "          [-4.8740e-02, -3.3823e-02,  9.3625e-03, -4.6259e-02, -5.5947e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.2760e-02,  9.5385e-03, -1.7847e-02,  1.1283e-03,  1.8096e-02],\n",
      "          [-2.9243e-02, -3.1248e-02, -9.0541e-02, -4.0697e-02, -2.0687e-02],\n",
      "          [-7.6654e-02, -1.5209e-02, -1.1412e-02, -3.5580e-02, -3.3807e-02],\n",
      "          [-3.1819e-02,  5.8109e-03,  6.5222e-02,  6.0017e-02, -3.3227e-02],\n",
      "          [ 3.0720e-02,  6.8331e-02,  5.0483e-02,  6.8235e-02, -8.4011e-03]],\n",
      "\n",
      "         [[ 2.7069e-02, -2.2673e-02,  9.2411e-03,  2.7040e-02, -4.4071e-03],\n",
      "          [-3.4780e-02,  1.5378e-02, -4.5299e-03,  2.8011e-02,  3.6252e-02],\n",
      "          [-4.6105e-03,  1.0865e-02, -5.8862e-03,  1.9164e-02,  7.2644e-02],\n",
      "          [-4.9121e-03,  6.2942e-02, -2.5401e-03, -4.7740e-03, -3.5339e-03],\n",
      "          [-4.3750e-02,  1.5396e-02,  5.2106e-02,  1.8609e-02,  1.6384e-02]],\n",
      "\n",
      "         [[ 3.4948e-02, -1.9948e-02,  5.9970e-03,  5.3295e-02, -6.1597e-03],\n",
      "          [-1.0717e-02, -1.6225e-02,  4.3348e-02,  1.9374e-02,  1.3709e-03],\n",
      "          [ 2.5759e-02, -1.3430e-02, -4.7083e-02, -6.9176e-03, -6.9491e-03],\n",
      "          [-1.8337e-03,  2.1917e-02,  7.7167e-03,  1.1171e-04,  3.7021e-02],\n",
      "          [ 2.0363e-02,  3.2173e-02,  3.1716e-02,  1.9626e-02, -2.9933e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7082e-02,  4.7179e-02,  1.6171e-02,  4.8903e-02,  1.8242e-02],\n",
      "          [ 6.8590e-02,  1.5749e-02,  8.5549e-02,  2.8968e-02,  4.4793e-02],\n",
      "          [-2.3889e-02, -5.1479e-02, -5.9440e-02, -2.2593e-02, -3.1265e-02],\n",
      "          [-1.8777e-02,  4.4715e-02,  4.2762e-02, -3.9814e-03,  5.7810e-03],\n",
      "          [ 4.3114e-02,  2.6329e-03,  2.9813e-02, -8.9512e-03, -9.7209e-03]],\n",
      "\n",
      "         [[-2.6765e-02, -5.6855e-02,  1.4670e-02,  1.2898e-02,  4.3167e-02],\n",
      "          [ 2.1687e-02, -1.0520e-02,  6.3631e-03,  2.8562e-02, -1.0351e-02],\n",
      "          [ 1.3370e-02,  6.1635e-03,  2.3880e-02, -5.7365e-02, -2.3172e-02],\n",
      "          [-1.9224e-02, -1.0102e-02, -3.4483e-03, -2.9223e-02, -9.2988e-03],\n",
      "          [ 2.6733e-02, -1.3333e-02,  1.1212e-02, -4.4154e-03, -2.2673e-02]],\n",
      "\n",
      "         [[-7.6397e-03,  5.1678e-02,  9.0808e-04,  5.0089e-02, -1.6981e-02],\n",
      "          [-3.3502e-03,  5.1996e-02,  1.5275e-02, -1.6032e-03, -3.1102e-02],\n",
      "          [-2.8363e-02, -6.1486e-02, -6.1812e-02, -6.2716e-02, -5.1348e-02],\n",
      "          [-5.2233e-02, -7.9736e-02, -4.2091e-02, -8.6085e-02, -6.4672e-02],\n",
      "          [ 4.5880e-02, -1.2661e-02, -6.6522e-02, -4.5086e-02, -3.5932e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3258e-02, -4.2456e-02, -3.6296e-02, -1.4303e-02,  5.8914e-03],\n",
      "          [-7.8205e-03, -3.9576e-02, -3.4568e-02, -3.8738e-02,  9.3593e-03],\n",
      "          [ 2.6133e-02,  3.5174e-02, -2.4005e-02, -4.7101e-02, -9.2380e-03],\n",
      "          [ 4.1617e-02,  9.9365e-03,  3.7829e-02,  3.3090e-03, -1.8826e-02],\n",
      "          [ 2.9908e-02,  2.3001e-02,  7.7025e-03,  2.7352e-02,  4.2637e-04]],\n",
      "\n",
      "         [[-2.1302e-02, -6.6821e-02, -1.8153e-02, -2.7403e-02,  3.2038e-02],\n",
      "          [-1.9998e-02,  1.0507e-02,  2.7180e-02,  6.3740e-02, -9.5887e-03],\n",
      "          [-3.1842e-02,  2.7119e-04,  1.5868e-02, -2.0090e-02, -1.4803e-04],\n",
      "          [-5.9808e-02, -7.9957e-02, -4.4318e-02, -5.0046e-02, -1.5180e-02],\n",
      "          [-6.0476e-03,  1.1201e-02,  4.1789e-02, -2.5857e-03, -4.9774e-02]],\n",
      "\n",
      "         [[ 1.6403e-02,  2.6346e-02, -1.1748e-02,  3.6007e-02, -9.2679e-03],\n",
      "          [-4.4729e-02, -8.7650e-03, -2.4138e-03, -1.9501e-02, -2.7764e-02],\n",
      "          [-9.9800e-03, -4.3865e-02,  4.7020e-03,  8.8615e-03, -2.3204e-02],\n",
      "          [-5.1671e-03,  4.0683e-02, -3.4233e-02, -3.3520e-02, -2.7987e-04],\n",
      "          [-2.8380e-02, -8.2064e-03,  7.5020e-03, -2.1889e-02, -1.4542e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1647e-02,  9.8722e-03,  2.2844e-02,  1.5381e-02,  9.5742e-04],\n",
      "          [ 6.2601e-02,  1.2936e-02,  2.4897e-02,  1.6378e-02,  7.2566e-02],\n",
      "          [-8.1432e-03,  8.7754e-03, -1.0599e-02,  6.5185e-03, -1.4714e-02],\n",
      "          [-1.0576e-02,  4.0042e-02, -1.6958e-02, -5.1538e-02, -6.5405e-02],\n",
      "          [-1.9963e-02,  5.7178e-02,  1.8143e-02,  2.7286e-02, -4.3964e-02]],\n",
      "\n",
      "         [[ 9.6604e-04, -2.1416e-02, -1.6947e-02,  1.3823e-03, -2.9819e-02],\n",
      "          [ 2.7193e-02,  1.4748e-02,  4.1970e-02,  7.1715e-03, -1.1290e-02],\n",
      "          [-1.4150e-02,  1.1073e-02,  3.5393e-03, -5.5969e-02, -1.4350e-02],\n",
      "          [ 1.2133e-02,  4.4129e-03, -3.6836e-02, -2.9228e-02,  8.7492e-03],\n",
      "          [-1.4717e-02, -2.3900e-02, -3.1753e-02,  8.8428e-03,  3.5834e-02]],\n",
      "\n",
      "         [[-9.5464e-04,  4.1828e-02, -7.0424e-03, -3.6266e-02, -7.9060e-02],\n",
      "          [-1.3314e-02,  1.8668e-02,  2.9570e-02, -4.9405e-02, -4.7647e-03],\n",
      "          [ 8.1872e-03,  2.3359e-02,  3.9599e-02,  4.2539e-02,  6.1623e-02],\n",
      "          [ 2.3556e-02, -3.3243e-02,  2.7955e-02,  7.7375e-02,  3.9349e-02],\n",
      "          [ 7.1756e-03,  3.8567e-03,  3.0633e-02,  2.3670e-02, -6.3064e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9404e-02, -7.3897e-03, -4.4997e-03,  4.7180e-03,  3.9922e-02],\n",
      "          [ 2.3705e-02,  4.6975e-03, -2.0801e-02,  1.8393e-03,  9.1557e-02],\n",
      "          [ 1.3893e-03, -2.6849e-02, -2.3006e-02,  5.3661e-03,  9.3120e-03],\n",
      "          [-3.4645e-03,  5.7488e-02,  1.2763e-03, -3.2373e-02, -6.2418e-02],\n",
      "          [ 5.7449e-02,  3.3011e-02,  3.3695e-02, -3.0416e-02, -6.9819e-03]],\n",
      "\n",
      "         [[-2.1085e-03, -9.1333e-03,  5.0668e-02,  1.4368e-02,  5.0941e-02],\n",
      "          [ 5.1437e-02, -2.2803e-02,  2.1357e-02,  3.3142e-02,  6.5145e-02],\n",
      "          [ 7.2093e-02, -5.3157e-03, -1.1538e-02,  7.7128e-02, -4.9793e-02],\n",
      "          [ 7.4700e-02,  8.2593e-02,  7.7150e-03, -4.3553e-02,  2.1474e-02],\n",
      "          [ 1.9892e-02,  1.3055e-02, -3.4471e-03,  6.2080e-03,  5.7328e-02]],\n",
      "\n",
      "         [[ 3.6559e-02, -3.5694e-02,  2.9695e-02, -2.3079e-02,  1.1769e-02],\n",
      "          [-2.4219e-02, -1.3238e-02,  9.2412e-03,  1.2963e-02, -1.0355e-02],\n",
      "          [-2.4760e-02,  1.1701e-02, -2.3397e-03,  8.9020e-03,  4.6680e-02],\n",
      "          [-5.8265e-02, -1.9643e-02,  5.3759e-02,  3.6490e-02, -5.9046e-02],\n",
      "          [-1.7547e-02,  1.6464e-03, -3.4696e-02, -2.9706e-02,  3.0156e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.5497e-02,  3.8217e-02, -3.9182e-02, -1.7456e-02, -2.7266e-02],\n",
      "          [-2.9916e-02,  4.8937e-02,  5.0238e-02,  4.7319e-02, -4.6461e-02],\n",
      "          [-1.3942e-02, -8.8395e-03,  5.5816e-02,  8.8733e-02,  1.2283e-02],\n",
      "          [ 4.0016e-03, -5.5375e-03, -2.0213e-02,  2.1302e-02, -8.1012e-03],\n",
      "          [-3.5581e-02, -5.5454e-02, -5.5039e-02, -3.2959e-02, -5.2002e-03]],\n",
      "\n",
      "         [[-2.3982e-02, -8.6600e-03,  2.4654e-03,  1.1930e-02, -4.7281e-02],\n",
      "          [-8.3945e-02, -2.1411e-02,  2.2507e-02,  4.1458e-03, -6.1013e-03],\n",
      "          [-3.3349e-02, -9.7731e-03, -2.3672e-02,  5.0027e-02,  4.3255e-02],\n",
      "          [-5.3585e-02, -7.4538e-02, -5.1981e-02,  4.5554e-02,  3.9396e-02],\n",
      "          [-5.0650e-02, -7.3799e-02, -5.0275e-02,  6.9693e-02,  5.4703e-02]],\n",
      "\n",
      "         [[ 1.1070e-02, -1.7337e-02,  4.6368e-02,  6.1625e-04, -1.5068e-02],\n",
      "          [-8.3226e-03,  1.9894e-02, -5.3888e-02, -4.7881e-02, -7.9432e-03],\n",
      "          [ 4.1364e-02,  6.4743e-03, -4.8996e-02, -5.2239e-02, -1.3777e-02],\n",
      "          [ 1.0246e-02,  1.2640e-03, -2.4352e-02, -4.5867e-02, -4.3516e-02],\n",
      "          [-2.4513e-03, -1.2506e-02,  2.9288e-02,  3.5048e-02, -1.3914e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2367e-02,  4.6139e-02,  2.4550e-02, -4.2955e-02, -6.0003e-03],\n",
      "          [-2.7460e-02,  7.0945e-03,  2.9377e-02,  1.0437e-02, -2.4816e-02],\n",
      "          [-6.9481e-02, -9.3534e-03,  2.3774e-02,  4.9605e-02,  5.8840e-02],\n",
      "          [-5.2180e-02, -1.4856e-02,  2.5938e-03,  3.0566e-02,  7.9085e-02],\n",
      "          [-3.9846e-02, -8.1846e-02, -5.8834e-02,  1.9716e-02,  2.0020e-02]],\n",
      "\n",
      "         [[ 2.1516e-02,  2.1075e-03, -5.7269e-02, -1.4910e-02, -4.3481e-03],\n",
      "          [ 2.6247e-02, -5.6011e-03,  4.3457e-02,  1.3610e-02, -6.6823e-02],\n",
      "          [-4.5043e-02, -3.5911e-02,  2.6206e-02,  4.0963e-02, -6.9935e-02],\n",
      "          [-2.5800e-02,  1.6481e-03,  4.9610e-03,  5.8208e-02,  4.9787e-02],\n",
      "          [ 2.1833e-03, -1.4704e-02, -2.0553e-03,  3.4305e-02, -1.2999e-02]],\n",
      "\n",
      "         [[ 6.4719e-03,  3.3506e-02, -2.5412e-02, -2.3365e-02, -3.9067e-02],\n",
      "          [ 5.1559e-02,  3.4608e-02, -1.4761e-02,  1.7024e-02,  5.8847e-03],\n",
      "          [ 3.1648e-02,  1.7279e-02, -1.1181e-02, -6.4107e-02, -3.9185e-02],\n",
      "          [ 3.1283e-03,  1.6485e-02,  1.4289e-02, -2.7593e-03, -7.9747e-02],\n",
      "          [ 4.7541e-02,  1.1666e-02, -1.1808e-02,  1.6250e-02, -4.5853e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2177e-02, -1.0699e-02,  8.5291e-03, -2.5339e-02, -3.2873e-02],\n",
      "          [-1.9845e-02, -3.8027e-02,  1.2863e-02,  5.1101e-03, -3.3484e-02],\n",
      "          [ 2.5387e-02,  2.1404e-03,  1.9424e-02,  1.1747e-03, -2.6366e-02],\n",
      "          [ 7.7114e-03, -4.7648e-03,  1.6162e-02, -1.9487e-02, -2.5309e-02],\n",
      "          [-3.1797e-02, -1.0209e-02,  5.1382e-03, -3.7107e-03, -1.5238e-02]],\n",
      "\n",
      "         [[-3.6250e-02, -1.1720e-02, -2.1559e-02, -2.8546e-02, -3.9222e-02],\n",
      "          [ 7.9236e-03, -3.4127e-02,  1.0073e-02, -2.8045e-02,  1.5645e-02],\n",
      "          [ 8.5237e-03,  1.8653e-02, -2.0692e-02, -3.5908e-02,  1.2858e-02],\n",
      "          [-9.7912e-03,  1.2236e-02,  2.6702e-02,  3.0891e-02, -9.8759e-03],\n",
      "          [ 2.5385e-02,  1.9186e-04, -1.9682e-02, -5.1661e-04,  2.0048e-02]],\n",
      "\n",
      "         [[ 2.3142e-02, -3.6019e-02, -1.3406e-02,  2.0316e-02,  2.2756e-02],\n",
      "          [ 3.0189e-03, -1.8101e-02,  2.2277e-02, -1.3226e-02, -1.0406e-02],\n",
      "          [ 4.7901e-03, -5.3294e-03, -2.9990e-02,  2.5743e-02,  2.7484e-02],\n",
      "          [-3.0122e-02, -1.8433e-02,  1.0837e-02, -8.6294e-04,  2.6080e-02],\n",
      "          [-1.9195e-03, -2.5702e-02,  1.6510e-02, -5.3082e-03, -2.4056e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.4376e-02,  1.8782e-02, -3.0479e-02,  1.4217e-02, -2.6690e-02],\n",
      "          [-2.1068e-02, -1.2298e-02, -1.2450e-02,  2.6380e-02, -1.0399e-03],\n",
      "          [ 1.9323e-03, -1.7261e-02,  2.2067e-02, -2.5420e-03, -3.3431e-02],\n",
      "          [ 2.0397e-02, -3.3090e-02,  1.6248e-02, -1.4056e-02,  1.3331e-02],\n",
      "          [ 1.6314e-03,  1.6503e-02,  2.6170e-02, -1.4294e-02,  6.5651e-03]],\n",
      "\n",
      "         [[ 8.8159e-05, -3.7837e-02,  1.2267e-02,  2.3311e-03, -4.1940e-03],\n",
      "          [-1.0580e-02, -2.0673e-02, -2.2283e-02,  1.2064e-02,  2.8879e-02],\n",
      "          [-2.2765e-02, -1.3405e-02, -6.9877e-03, -3.5769e-02, -3.8183e-03],\n",
      "          [-3.3465e-02,  5.9266e-03,  2.3675e-02,  2.1754e-02, -7.6110e-03],\n",
      "          [ 3.1228e-02,  1.2106e-02, -9.6069e-03,  1.3991e-02, -2.2119e-02]],\n",
      "\n",
      "         [[-6.0450e-03,  1.8589e-02,  1.7275e-03,  4.4269e-03, -3.2387e-02],\n",
      "          [-2.4572e-02, -3.3024e-02, -2.8768e-02,  5.9699e-03, -2.8341e-03],\n",
      "          [-7.9995e-03, -2.3392e-02,  2.5178e-02, -3.7702e-02, -4.5084e-03],\n",
      "          [ 2.3300e-02,  7.3632e-05,  2.8141e-02, -2.0607e-02,  8.0109e-03],\n",
      "          [ 8.8190e-03,  3.2205e-02, -4.7638e-03, -3.7728e-02, -3.9749e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0290e-02, -1.2322e-02, -1.9364e-02, -4.3481e-04,  5.1175e-03],\n",
      "          [-1.1111e-02,  1.0786e-02, -8.2588e-03,  1.1492e-02,  2.4181e-03],\n",
      "          [-2.6444e-02, -3.3370e-02,  5.1210e-03, -1.1344e-02, -1.7678e-02],\n",
      "          [-2.0535e-02,  3.1128e-02,  3.5148e-02,  2.4001e-02, -2.6041e-02],\n",
      "          [-8.6797e-04,  8.4413e-03,  3.2905e-02,  1.0162e-03,  1.3024e-02]],\n",
      "\n",
      "         [[-1.5004e-02,  1.6179e-02, -2.6445e-03, -3.4975e-03, -3.9955e-02],\n",
      "          [-1.1416e-03,  3.6557e-02, -2.9132e-02,  2.4337e-02, -1.6105e-02],\n",
      "          [ 6.4895e-03,  2.6603e-02,  1.1720e-02,  1.0152e-03,  4.8533e-03],\n",
      "          [ 7.2476e-03,  3.3571e-02,  3.4722e-02, -1.5393e-02,  3.0847e-02],\n",
      "          [ 7.4459e-03, -4.4110e-03, -2.9668e-02, -3.2514e-02,  3.0573e-02]],\n",
      "\n",
      "         [[ 4.1889e-02, -1.1901e-02,  7.4122e-03,  1.7977e-02,  3.6544e-02],\n",
      "          [ 1.1712e-02,  1.4570e-02,  5.3692e-02, -7.9754e-03,  2.6512e-02],\n",
      "          [ 1.1500e-02,  4.1962e-02, -4.6771e-03, -1.0777e-02, -3.4980e-02],\n",
      "          [ 1.8492e-02, -3.0332e-02,  9.7452e-03,  1.6385e-02,  8.1669e-03],\n",
      "          [-7.4848e-03, -1.7741e-02,  2.7052e-02,  4.5552e-03,  8.7849e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0363e-02,  1.2541e-02,  3.4322e-04,  1.1973e-02,  7.6252e-03],\n",
      "          [ 1.3088e-02,  1.3178e-02, -1.1403e-02,  1.5634e-02,  9.6048e-03],\n",
      "          [-1.0977e-02,  2.8131e-02,  1.7595e-02,  3.3078e-02,  3.6172e-02],\n",
      "          [ 5.1515e-02,  1.0639e-02,  5.3279e-02, -6.5357e-03,  2.3033e-02],\n",
      "          [ 3.1241e-02,  5.9131e-02,  3.2443e-02,  3.7094e-03,  1.6793e-02]],\n",
      "\n",
      "         [[ 3.5117e-03,  1.0488e-02,  3.1401e-02,  4.1982e-02,  2.5887e-02],\n",
      "          [ 1.0891e-02,  3.3949e-03,  2.7962e-02, -6.7070e-03,  1.6809e-02],\n",
      "          [ 2.3302e-02,  1.5888e-02,  1.5205e-02,  3.1233e-02,  3.7896e-03],\n",
      "          [ 2.2574e-02,  5.6160e-02,  1.0829e-02, -2.5982e-02,  9.2348e-03],\n",
      "          [-2.0244e-02,  2.7321e-03, -7.5742e-03, -2.2505e-03, -1.9324e-02]],\n",
      "\n",
      "         [[-2.1905e-02, -5.4246e-03,  1.2985e-02,  1.8632e-02,  3.8645e-02],\n",
      "          [ 2.2246e-02,  1.5783e-02,  4.2479e-02,  1.1609e-02, -1.4353e-02],\n",
      "          [-3.2878e-02, -2.8236e-02, -3.1240e-02, -2.4331e-02,  2.6607e-02],\n",
      "          [-1.6509e-02,  1.9139e-02, -1.0757e-02,  2.8458e-02,  1.8002e-02],\n",
      "          [-1.4271e-02, -3.2818e-02, -3.6945e-02, -1.7948e-03, -1.3066e-02]]]],\n",
      "       device='cuda:0')), ('conv_2.bias', tensor([-0.0182,  0.0286, -0.0356,  0.0048, -0.0123,  0.0027, -0.0216,  0.0143,\n",
      "        -0.0243, -0.0148,  0.0142, -0.0032,  0.0209, -0.0093, -0.0251, -0.0090,\n",
      "        -0.0017, -0.0054,  0.0270, -0.0181,  0.0164,  0.0094, -0.0108, -0.0060,\n",
      "         0.0043,  0.0055, -0.0235,  0.0191, -0.0206, -0.0230, -0.0030,  0.0309,\n",
      "        -0.0138, -0.0143,  0.0347,  0.0003, -0.0347,  0.0249,  0.0308,  0.0032,\n",
      "         0.0068, -0.0317, -0.0300, -0.0251,  0.0147, -0.0155,  0.0410,  0.0233,\n",
      "        -0.0355,  0.0306,  0.0068, -0.0254, -0.0019,  0.0070,  0.0085,  0.0199,\n",
      "        -0.0361, -0.0265, -0.0222, -0.0171, -0.0185,  0.0118, -0.0165,  0.0114],\n",
      "       device='cuda:0')), ('linear_1.weight', tensor([[-0.0156,  0.0109, -0.0254,  ..., -0.0413, -0.0143, -0.0168],\n",
      "        [-0.0230, -0.0302,  0.0086,  ..., -0.0328, -0.0142,  0.0093],\n",
      "        [-0.0234, -0.0533, -0.0112,  ...,  0.0138,  0.0003,  0.0341],\n",
      "        ...,\n",
      "        [-0.0845,  0.0098,  0.0202,  ..., -0.0176, -0.0090, -0.0093],\n",
      "        [ 0.0238,  0.0155,  0.0344,  ..., -0.0044,  0.0060,  0.0286],\n",
      "        [-0.0163, -0.0251, -0.0456,  ...,  0.0192,  0.0144,  0.0199]],\n",
      "       device='cuda:0')), ('linear_1.bias', tensor([-0.0058, -0.0301,  0.0188,  0.0292,  0.0173, -0.0224, -0.0185,  0.0117,\n",
      "         0.0231, -0.0267,  0.0084,  0.0215,  0.0217, -0.0141, -0.0356, -0.0271,\n",
      "         0.0091, -0.0082, -0.0214, -0.0069,  0.0020,  0.0294,  0.0181,  0.0040,\n",
      "        -0.0092,  0.0177,  0.0109,  0.0103,  0.0092,  0.0004,  0.0003, -0.0194,\n",
      "        -0.0165,  0.0048,  0.0257,  0.0044, -0.0300,  0.0120,  0.0137,  0.0299,\n",
      "        -0.0062, -0.0074,  0.0013,  0.0147, -0.0019,  0.0079, -0.0106, -0.0195,\n",
      "         0.0201, -0.0257,  0.0142, -0.0230, -0.0071,  0.0297, -0.0110,  0.0170,\n",
      "        -0.0284,  0.0077, -0.0130, -0.0248,  0.0291,  0.0014, -0.0280, -0.0101,\n",
      "        -0.0126,  0.0195, -0.0046,  0.0350,  0.0012,  0.0178,  0.0130, -0.0026,\n",
      "        -0.0094,  0.0298,  0.0294,  0.0135,  0.0069, -0.0239,  0.0289, -0.0232,\n",
      "        -0.0374, -0.0160,  0.0079, -0.0225, -0.0330,  0.0056,  0.0111,  0.0194,\n",
      "        -0.0192, -0.0051,  0.0063,  0.0056, -0.0066, -0.0256,  0.0255, -0.0027,\n",
      "        -0.0199, -0.0109, -0.0039, -0.0235,  0.0155, -0.0054, -0.0342,  0.0375,\n",
      "         0.0305, -0.0284,  0.0104,  0.0203,  0.0388, -0.0118, -0.0311, -0.0249,\n",
      "        -0.0034, -0.0017, -0.0240, -0.0018,  0.0246, -0.0091,  0.0192,  0.0161,\n",
      "         0.0101,  0.0210,  0.0040,  0.0327, -0.0093, -0.0250,  0.0208, -0.0330,\n",
      "         0.0211, -0.0071, -0.0287,  0.0077,  0.0304, -0.0217, -0.0161, -0.0248,\n",
      "        -0.0009, -0.0252, -0.0012, -0.0030,  0.0423,  0.0013, -0.0209, -0.0235,\n",
      "         0.0060, -0.0141,  0.0139,  0.0021, -0.0181, -0.0288,  0.0256, -0.0003,\n",
      "        -0.0210,  0.0123, -0.0174,  0.0053,  0.0274,  0.0127,  0.0178,  0.0201,\n",
      "         0.0316,  0.0176,  0.0216,  0.0004, -0.0022, -0.0270, -0.0086,  0.0190,\n",
      "         0.0132,  0.0051, -0.0376, -0.0138, -0.0341,  0.0400,  0.0090,  0.0319,\n",
      "         0.0262, -0.0041,  0.0248, -0.0284, -0.0081,  0.0003,  0.0266,  0.0057,\n",
      "        -0.0274,  0.0270, -0.0300,  0.0231, -0.0177,  0.0304, -0.0192, -0.0310,\n",
      "        -0.0168, -0.0230, -0.0373,  0.0273,  0.0273, -0.0158,  0.0119,  0.0366,\n",
      "        -0.0087,  0.0156, -0.0088,  0.0303,  0.0173, -0.0095,  0.0307,  0.0387,\n",
      "         0.0120,  0.0097,  0.0192,  0.0168,  0.0029,  0.0110, -0.0022, -0.0222,\n",
      "         0.0001,  0.0229,  0.0079, -0.0077,  0.0081, -0.0154, -0.0065, -0.0197,\n",
      "        -0.0233, -0.0112,  0.0196,  0.0134, -0.0283,  0.0006,  0.0254,  0.0310,\n",
      "        -0.0256, -0.0300, -0.0360, -0.0171,  0.0215, -0.0229, -0.0169, -0.0174,\n",
      "         0.0127,  0.0247, -0.0186, -0.0064,  0.0245, -0.0244, -0.0244, -0.0264,\n",
      "         0.0077,  0.0085,  0.0225,  0.0084,  0.0233,  0.0020, -0.0265, -0.0120],\n",
      "       device='cuda:0')), ('linear_2.weight', tensor([[ 0.0156,  0.0071, -0.0656,  ...,  0.0135, -0.0755, -0.0769],\n",
      "        [-0.0160, -0.0542, -0.0051,  ...,  0.0847, -0.0225,  0.0175],\n",
      "        [-0.0816, -0.0759, -0.0104,  ..., -0.0476,  0.0989,  0.0639],\n",
      "        ...,\n",
      "        [-0.0472, -0.0603, -0.0580,  ..., -0.0619,  0.0694,  0.0889],\n",
      "        [-0.0432, -0.0963, -0.0405,  ..., -0.0650, -0.0962, -0.0774],\n",
      "        [-0.0411,  0.0863, -0.0661,  ..., -0.0508,  0.0181, -0.0718]],\n",
      "       device='cuda:0')), ('linear_2.bias', tensor([ 0.0407,  0.0607,  0.0173,  0.0085,  0.0012, -0.0300, -0.0081,  0.0668,\n",
      "         0.0154, -0.0182], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as dset\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "image_x = 28\n",
    "image_y = 28\n",
    "image_channel = 1\n",
    "output_channel = 10\n",
    "\n",
    "class MNIST_NN(nn.Module):\n",
    "    def __init__(self, image_x, image_y, image_channel, output_channel):\n",
    "        super(MNIST_NN, self).__init__()\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(1, 32, kernel_size=(5,5))\n",
    "        self.conv_2 = nn.Conv2d(32, 64, kernel_size=(5,5))\n",
    "        \n",
    "        self.linear_1 = nn.Linear(1024, 256)\n",
    "        self.linear_2 = nn.Linear(256, output_channel)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        out = F.max_pool2d(F.relu(self.conv_1(image)), kernel_size=(2,2))\n",
    "        out = F.max_pool2d(F.relu(self.conv_2(out)), kernel_size=(2,2))\n",
    "        \n",
    "        out = self.linear_1(torch.flatten(out, 1))\n",
    "        out = self.linear_2(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "# GPU\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('GPU State:', device)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,)),]\n",
    ")\n",
    "train_data = datasets.MNIST(root='MNIST', download=True, train=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='MNIST', download=True, train=False, transform=transform)\n",
    "trainLoader = dset.DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "testLoader = dset.DataLoader(test_data, batch_size=1024, shuffle=False)\n",
    "\n",
    "\n",
    "model = MNIST_NN(image_x, image_y, image_channel, output_channel).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "batch_grad_norm = 0.0\n",
    "for epochs in range(3):\n",
    "    total_norm = 0.0\n",
    "    start = time.time()\n",
    "    for i, (data) in enumerate(trainLoader):\n",
    "        model.zero_grad()\n",
    "        \n",
    "        image = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "        \n",
    "        res = model(image)\n",
    "        \n",
    "        loss = loss_function(res, labels)\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}], Loss: {:.4f}, Acc : {:.4f}'.format(epochs + 1, num_epochs, i + 1, loss.item(), acc.item()))\n",
    "            \n",
    "        loss.backward()\n",
    "        if (i + 1) % 100 == 0:\n",
    "            batch_grad_norm = 0.0\n",
    "            for p in model.parameters():\n",
    "                param_norm = p.grad.detach().data.norm(2)\n",
    "                batch_grad_norm += param_norm.item() ** 2\n",
    "            total_norm = total_norm + batch_grad_norm ** 0.5\n",
    "        optimizer.step()\n",
    "    \n",
    "    print((time.time() - start) / len(trainLoader))\n",
    "    print(total_norm)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (image, tags) in enumerate(testLoader):\n",
    "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
    "        probs = model(bow_vec)\n",
    "       \n",
    "        print(nn.Softmax(dim=1)(probs))\n",
    "        \n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f87d25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
